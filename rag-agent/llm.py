import os
from typing import List, Dict, Optional
from openai import OpenAI
from dotenv import load_dotenv
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Initialize OpenAI client
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

class LLMHandler:
    def __init__(self, model_name: str = "gpt-3.5-turbo"):
        """
        Initialize the LLM handler.
        
        Args:
            model_name: Name of the OpenAI model to use
        """
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("OPENAI_API_KEY not found in environment variables")
            
        self.client = OpenAI(api_key=self.api_key)
        self.model_name = model_name
        logger.info(f"LLM handler initialized with model: {model_name}")
    
    def generate_response(self, 
                         query: str, 
                         context: List[Dict], 
                         conversation_history: Optional[str] = None) -> Dict:
        """
        Generate a response using the LLM.
        
        Args:
            query: User query
            context: Retrieved context from RAG system
            conversation_history: Optional conversation history string
            
        Returns:
            Dict: Response containing text and optional audio
        """
        try:
            # Format the context
            context_text = "\n\n".join([f"Document {i+1}:\n{chunk['text']}" 
                                      for i, chunk in enumerate(context)])
            
            # Create the system message with context and conversation history
            system_message = "You are a helpful AI assistant. Use the following context to answer the user's question."
            if conversation_history:
                system_message += f"\n\n{conversation_history}"
            if context_text:
                system_message += f"\n\nRelevant context:\n{context_text}"

            # Check if the query is asking for a comparison or table format
            query_lower = query.lower()
            is_comparison = any(keyword in query_lower for keyword in ["compare", "differences", "versus", "vs", "table", "format as table"])

            if is_comparison:
                system_message += """
When formatting tables, follow these rules:
1. Use proper Markdown table syntax with headers and alignment
2. Include a clear title for the table using ### or #### heading
3. Ensure all columns are properly aligned using :---: for center, :--- for left, ---: for right
4. Use consistent formatting for similar data
5. Add brief explanations if needed
6. Format the table like this:

### Table Title
| Header 1 | Header 2 | Header 3 |
|:--------:|:---------|---------:|
| Data 1   | Data 2   | Data 3   |
| Data 4   | Data 5   | Data 6   |

For document comparisons, use this format:

### Document Comparison
ðŸ“„ Document 1 Name
| Aspect | Details |
|:-------|:--------|
| Point 1 | Info 1  |
| Point 2 | Info 2  |

ðŸ“„ Document 2 Name
| Aspect | Details |
|:-------|:--------|
| Point 1 | Info 1  |
| Point 2 | Info 2  |

Always ensure tables are properly aligned and formatted for readability.
"""

            # Single response
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": query}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            return {"responses": [response.choices[0].message.content.strip()], "audio": None}
        except Exception as e:
            logger.error(f"Error generating response: {str(e)}")
            return {"responses": ["I apologize, but I encountered an error while generating the response. Please try again."], "audio": None}